{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import & CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(132) # Fix the seed\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(torch.cuda.get_device_name())\n",
    "else:\n",
    "    raise PermissionError(\"CUDA is not usable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_ds_simclr = datasets.ImageFolder(\n",
    "    root='./train',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f\"Train dataset size for SimCLR : {len(train_ds_simclr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = Counter(train_ds_simclr.targets)\n",
    "for class_idx, count in class_counts.items():\n",
    "    print(f\"Classe '{train_ds_simclr.classes[class_idx]}' : {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_limited_indices(dataset, max_samples_per_class=50):\n",
    "    class_counts = {cls_idx: 0 for cls_idx in range(len(dataset.classes))}\n",
    "    limited_indices = []\n",
    "\n",
    "    for idx, (_, label) in enumerate(dataset):\n",
    "        if class_counts[label] < max_samples_per_class:\n",
    "            limited_indices.append(idx)\n",
    "            class_counts[label] += 1\n",
    "\n",
    "        # Stop if enough samples\n",
    "        if all(count >= max_samples_per_class for count in class_counts.values()):\n",
    "            break\n",
    "\n",
    "    return limited_indices\n",
    "\n",
    "limited_indices = get_limited_indices(train_ds_simclr, max_samples_per_class=50)\n",
    "\n",
    "train_classifier_ds = Subset(train_ds_simclr, limited_indices)\n",
    "\n",
    "train_classifier_loader = DataLoader(\n",
    "    train_classifier_ds,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Size of the dataset to train the classifier : {len(train_classifier_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds_classifier = datasets.ImageFolder(\n",
    "    root='./val',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "val_classifier_loader = DataLoader(\n",
    "    val_ds_classifier,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_ds_classifier = datasets.ImageFolder(\n",
    "    root='./test',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_classifier_loader = DataLoader(\n",
    "    test_ds_classifier,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Basic CNN\n",
    "\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(64*64*16,128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "        self.dp = nn.Dropout(p=0.3)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) # (3, 256, 256) -> (16, 256, 256)     1 + (H-K+2*P)/S\n",
    "        x = self.relu(x) \n",
    "        x = self.pool(x) # (16, 256, 256) -> (16, 128, 128)\n",
    "        x = self.dp(x)\n",
    "        \n",
    "        x = self.conv2(x) # (16, 128, 128) -> (32, 128, 128)    \n",
    "        x = self.relu(x) \n",
    "        x = self.pool(x) # (32, 128, 128) -> (32, 64, 64)\n",
    "        x = self.dp(x)\n",
    "        \n",
    "        x = self.flatten(x) # (64, 32, 32) -> (64*32*32) same as x.view(x.size(0), -1)  \n",
    "        x = self.fc1(x) # (64*32*32) -> (128)\n",
    "        x = self.dp(x)\n",
    "        x = self.fc2(x) # (128) -> (num_classes)\n",
    "        x = self.dp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model CNN1\n",
    "\n",
    "class CNN1(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64*32*32, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.dp = nn.Dropout(p=0.3)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) # (3, 256, 256) -> (16, 256, 256)     1 + (H-K+2*P)/S\n",
    "        x = self.relu(x) \n",
    "        x = self.pool(x) # (16, 256, 256) -> (16, 128, 128)\n",
    "        x = self.dp(x)\n",
    "        \n",
    "        x = self.conv2(x) # (16, 128, 128) -> (32, 128, 128)    \n",
    "        x = self.relu(x) \n",
    "        x = self.pool(x) # (32, 128, 128) -> (32, 64, 64)\n",
    "        x = self.dp(x)\n",
    "        \n",
    "        x = self.conv3(x) # (32, 64, 64) -> (64, 64, 64)  \n",
    "        x = self.relu(x) \n",
    "        x = self.pool(x) # (64, 32, 32) -> (64, 32, 32)\n",
    "        x = self.dp(x)\n",
    "        \n",
    "        x = self.flatten(x) # (64, 32, 32) -> (64*32*32) same as x.view(x.size(0), -1)  \n",
    "        x = self.fc1(x) # (64*32*32) -> (128)\n",
    "        x = self.dp(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "epochs = 20\n",
    "num_classes = len(train_ds_simclr.classes)\n",
    "\n",
    "\n",
    "model = BasicCNN(num_classes).to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for image, label in train_classifier_loader:\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(image)\n",
    "        loss = criterion(pred, label)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Train accuracy\n",
    "        train_loss += loss.item() * image.size(0)\n",
    "        _, predicted = torch.max(pred, dim=1) \n",
    "        train_correct += (predicted == label).sum().item()\n",
    "        train_total += label.size(0)\n",
    "\n",
    "    train_accuracy = train_correct / train_total\n",
    "    train_loss = train_loss / train_total\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in val_classifier_loader:\n",
    "            image, label = image.to(device), label.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            pred = model(image)\n",
    "            loss = criterion(pred, label)\n",
    "\n",
    "            # Val accuracy\n",
    "            val_loss += loss.item() * image.size(0)\n",
    "            _, predicted = torch.max(pred, dim=1) \n",
    "            val_correct += (predicted == label).sum().item()\n",
    "            val_total += label.size(0)\n",
    "\n",
    "    val_accuracy = val_correct / val_total\n",
    "    val_loss = val_loss / val_total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"CNN.pth\")\n",
    "# print(\"Saved model parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for image, label in test_classifier_loader:\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(image)\n",
    "        loss = criterion(pred, label)\n",
    "\n",
    "        # Test accuracy\n",
    "        test_loss += loss.item() * image.size(0)\n",
    "        _, predicted = torch.max(pred, dim=1) \n",
    "        test_correct += (predicted == label).sum().item()\n",
    "        test_total += label.size(0)\n",
    "\n",
    "test_accuracy = test_correct / test_total\n",
    "test_loss = test_loss / test_total\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for SimCLR\n",
    "transform_simclr = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomResizedCrop(size=128, scale=(0.2, 1.0)),\n",
    "            transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# SimCLR dataset\n",
    "class SimCLRDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, transform):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.dataset[idx]\n",
    "\n",
    "\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img = transforms.ToPILImage()(img)\n",
    "\n",
    "        img1 = self.transform(img)  # Augmented view 1\n",
    "        img2 = self.transform(img)  # Augmented view 2\n",
    "        # img1 and img2 are a positive pair and all the other view are negative pairs for each image\n",
    "\n",
    "        return img1, img2, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "simclr_train_ds = SimCLRDataset(train_ds_simclr, transform_simclr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderImproved(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderImproved, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),  \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), \n",
    "            nn.Dropout(p=0.3),\n",
    "        ) \n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),  \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), \n",
    "            nn.Dropout(p=0.3),\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),  \n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  \n",
    "            nn.Dropout(p=0.3),\n",
    "        ) \n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((4, 4)) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x) # (64, 64, 64)\n",
    "        x = self.layer2(x) # (128, 32, 32)\n",
    "        x = self.layer3(x) # (256, 16, 16)\n",
    "        x = self.global_avg_pool(x) # (256, 4, 4)\n",
    "        x = x.view(x.size(0), -1)  # Flatten (256 * 4 * 4)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=256*4*4, output_dim=64):\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTXentLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super(NTXentLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        z_i = F.normalize(z_i, dim=1)\n",
    "        z_j = F.normalize(z_j, dim=1)\n",
    "        similarity_matrix = torch.mm(z_i, z_j.T)\n",
    "        labels = torch.arange(z_i.size(0)).to(z_i.device)\n",
    "        loss = F.cross_entropy(similarity_matrix / self.temperature, labels)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderImproved().to(device)\n",
    "projection_head = ProjectionHead().to(device)\n",
    "criterion = NTXentLoss(temperature=0.5)\n",
    "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(projection_head.parameters()), lr=1e-3)\n",
    "\n",
    "for epoch in range(5):\n",
    "    encoder.train()\n",
    "    projection_head.train()\n",
    "    total_loss = 0\n",
    "    for img1, img2, _ in DataLoader(simclr_train_ds, batch_size=128, shuffle=True):\n",
    "        img1, img2 = img1.to(device), img2.to(device)\n",
    "        h1, h2 = encoder(img1), encoder(img2)\n",
    "        z1, z2 = projection_head(h1), projection_head(h2)\n",
    "        loss = criterion(z1, z2)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(simclr_train_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), \"encoder.pth\")\n",
    "torch.save(projection_head.state_dict(), \"projection_head.pth\")\n",
    "torch.save(optimizer.state_dict(), \"optimizer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(256*4*4, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 25)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "            x = self.encoder(x)\n",
    "            x = self.mlp(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier(encoder).to(device)\n",
    "for param in classifier.encoder.parameters():\n",
    "    param.requires_grad = False # Freeze the parameters of the encoder that we already trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(classifier.mlp.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train_classifier(model, train_loader, val_loader, criterion, optimizer, device, epochs=10):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Training loop\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Loss\n",
    "            total_loss += loss.item()\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        # Training accuracy\n",
    "        train_accuracy = correct / total * 100\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for val_images, val_labels in val_loader:\n",
    "                val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "\n",
    "                val_outputs = model(val_images)\n",
    "                val_predictions = torch.argmax(val_outputs, dim=1)\n",
    "                val_correct += (val_predictions == val_labels).sum().item()\n",
    "                val_total += val_labels.size(0)\n",
    "\n",
    "        val_accuracy = val_correct / val_total * 100\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.2f}%, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "train_classifier(classifier, train_classifier_loader, val_classifier_loader, criterion, optimizer, device, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.eval()\n",
    "\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():  \n",
    "    for image, label in test_classifier_loader:\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred = classifier(image)\n",
    "        loss = criterion(pred, label)\n",
    "\n",
    "        # Test accuracy\n",
    "        test_loss += loss.item() * image.size(0)\n",
    "        _, predicted = torch.max(pred, dim=1) \n",
    "        test_correct += (predicted == label).sum().item()\n",
    "        test_total += label.size(0)\n",
    "\n",
    "test_accuracy = test_correct / test_total\n",
    "test_loss = test_loss / test_total\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
